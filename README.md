
<img src="https://i.ibb.co/brLjgmh/attn.png" width="500"><br/>


**NLP-course** 


This is an excellent course in terms of giving an overview, quite in-depth, into the all the main achievements in the NLP field, accelerating from text preprocessing to state-of-the-art transformer models like T5 and GPT-2, GPT-3.

For all new comers to the field, like me, this course is full of insights and practical codes, helping to construct advanced model architectures from scratch and step-by-step.

The course link can be found [here](https://www.coursera.org/specializations/natural-language-processing ), and is divided in 4 parts, which can be summarized as follows:

Part 1.
This part covers sentiment analysis of tweets using logistic regression and naïve Bayes, PCA dimensionality reduction, translation algorithm using word embeddings and kNN search using locality sensitive hashing

Part 2.
Probabilistic models are the focus of the second NLP course, demonstrating Viterbi Algorithm for part-of-speech (POS) tagging, auto-correct using minimum edit distance and dynamic programming, and auto-complete using an N-grams

Part 3.
In this course, instructors demonstrate how to generate synthetic Shakespeare text with GRU cells, train a NER model using LSTMs with linear layers, and ‘Siamese’ LSTM models to identify similar questions on a Stackoverflow corpora

Part 4.
The last course ccompletes the following tasks:  English-German translation via encoder-decoder attention model, usng transformer model to summarize text, question-answering with T5 and BERT, and finally build a chatbot using a Reformer model





